# AlgoKit Examples Explorer - Backend API

Backend service for semantic search over AlgoKit examples using LanceDB vector database and Transformers.js embeddings.

## Architecture

- **Framework**: Fastify (Node.js)
- **Database**: LanceDB (vector database with native Rust bindings)
- **Embeddings**: Transformers.js with `all-MiniLM-L6-v2` model
- **API**: REST API with JSON schema validation

## Prerequisites

- Node.js ≥22
- npm or pnpm

## Installation

```bash
cd backend
npm install
```

## Development

```bash
npm run dev
```

Server starts on `http://localhost:3001`

**First run**: Downloads the embedding model (~25MB) to `.cache/` directory. This takes 10-20 seconds. Subsequent runs are instant.

## API Endpoints

### POST /api/search

Semantic search over AlgoKit examples.

**Request:**
```json
{
  "query": "create algorand account",
  "limit": 10
}
```

**Response:**
```json
{
  "results": [
    {
      "example_id": "01-account-creation-and-funding",
      "title": "Account Creation and Funding",
      "summary": "...",
      "repository": "algokit-utils-ts",
      "language": "typescript",
      "complexity": "simple",
      "feature_tags": ["account-management", "funding"],
      "features_to_demonstrate": [...],
      "target_users": [...],
      "similarity": 87.5,
      "_distance": 0.25
    }
  ],
  "query": "create algorand account",
  "count": 10,
  "processingTimeMs": 234
}
```

### GET /api/examples/:id

Get a single example by ID.

**Request:**
```
GET /api/examples/01-account-creation-and-funding
```

**Response:**
```json
{
  "example_id": "01-account-creation-and-funding",
  "title": "Account Creation and Funding",
  ...
}
```

Returns `404` if example not found.

### GET /api/health

Health check endpoint.

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2025-11-03T...",
  "services": {
    "database": true,
    "embedder": true
  },
  "examplesCount": 37
}
```

## Project Structure

```
backend/
├── src/
│   ├── index.ts           # Fastify server entry point
│   ├── routes/
│   │   └── api.ts         # API route definitions
│   ├── services/
│   │   ├── database.ts    # LanceDB initialization
│   │   ├── embedder.ts    # Query embedding service
│   │   └── search.ts      # Search orchestration
│   └── schemas/
│       └── search.ts      # TypeBox validation schemas
├── data/
│   ├── embeddings.json    # Pre-computed embeddings (37 examples)
│   └── algokit-examples-db/  # LanceDB database files
├── package.json
└── tsconfig.json
```

## Data Pipeline

### Pre-computed Embeddings

The `data/embeddings.json` file contains 37 AlgoKit examples with pre-computed 384-dimensional embeddings.

Generated by the Python pipeline in `embeddings/` directory using:
- Model: `sentence-transformers/all-MiniLM-L6-v2`
- Normalization: L2 normalized vectors
- Dimensions: 384

### Query Embeddings

User queries are embedded on-demand using the same model via Transformers.js, ensuring vector compatibility.

## Performance

- **Initial startup**: 10-20s (model download, first time only)
- **Subsequent startups**: 2-5s (model cached)
- **Search latency**: 200-500ms (embedding + vector search)
- **Memory usage**: ~200-300MB (loaded model)

## Configuration

### CORS

Currently configured for local development:
```typescript
origin: ['http://localhost:3000']
```

For production, update in `src/index.ts`.

### Port

Default: `3001`

Change in `src/index.ts`:
```typescript
await server.listen({ port: 3001, host: '0.0.0.0' })
```

## Scripts

- `npm run dev` - Start development server with hot reload (tsx watch)
- `npm run build` - Compile TypeScript to JavaScript
- `npm start` - Start production server
- `npm run lint` - Type check without emitting files

## Error Handling

The API uses consistent error responses:

```json
{
  "statusCode": 400,
  "error": "Bad Request",
  "message": "body/query must NOT be shorter than 1 characters"
}
```

Status codes:
- `200` - Success
- `400` - Bad Request (validation error)
- `404` - Not Found (example not found)
- `500` - Internal Server Error

## Logging

Uses Fastify's built-in Pino logger for structured JSON logs:

```json
{"level":30,"time":1699...,"msg":"Search request received","query":"create account"}
{"level":30,"time":1699...,"msg":"Search completed","count":10,"processingTimeMs":234}
```

## Testing

```bash
# Health check
curl http://localhost:3001/api/health

# Search
curl -X POST http://localhost:3001/api/search \
  -H "Content-Type: application/json" \
  -d '{"query": "create account", "limit": 5}'

# Get by ID
curl http://localhost:3001/api/examples/01-account-creation-and-funding
```

## Deployment

### Docker (Recommended)

```dockerfile
FROM node:22-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --production
COPY . .
RUN npm run build
EXPOSE 3001
CMD ["npm", "start"]
```

### Environment Variables

- `NODE_ENV` - Set to `production` for production builds
- `PORT` - Override default port (optional)

### Hosting Options

- Railway
- Render
- Fly.io
- Google Cloud Run
- AWS ECS

## License

MIT